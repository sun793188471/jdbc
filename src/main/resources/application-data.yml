# ------------------------------------连接池配置------------------------------------------
spring:
  main:
    allow-bean-definition-overriding: true
  shardingsphere:
    mode:
      # 将运行模式配置为Standalone单机模式（Cluster：集群模式）
      type: Standalone
      repository:
        type: JDBC
    # 配置多个数据源
    datasource:
      names: ds0,ds1
      # 配置第一个数据源
      ds0:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://10.128.163.160:3306/jdbc1?useSSL=false&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&rewriteBatchedStatements=true
        username: cloudwalk
        password: Cloudwalk@123!
      # 配置第二个数据源
      ds1:
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://10.128.163.160:3306/jdbc2?useSSL=false&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&rewriteBatchedStatements=true
        username: cloudwalk
        password: Cloudwalk@123!
    # 执行时显示SQL语句
    props:
      # 日志显示具体的SQL
      sql-show: true
    # 配置分片规则
    rules:
      # 配置分片策略
      sharding:
        # 配置所有分片表
        tables:
          # 首先配置商品表的分片策略
          shoping:
            # 声明商品表所在的真实数据节点（这里先显式声明一个节点测试）
            actual-data-nodes: ds$->{0..1}.shoping_0$->{0..1}
            # 配置shoping表的主键生成策略
            key-generate-strategy:
              # 声明主键为shoping_id
              column: shoping_id
              # 同样指向global-id-snowflake这个具体的主键生成策略
              keygenerator-name: global-id-snowflake
            # 配置分表规则
            table-strategy:
              standard:
                # 配置分表的路由键：商品名称
                sharding-column: shoping_name
                sharding-algorithm-name: key-hash-mod
            # 配置分库规则
            database-strategy:
              standard:
                # 配置路由键为shoping_id（数据库中的列名）
                sharding-column: shoping_id
                # 配置分片算法（需要配置一个名词，通过别名指向具体的策略）
                sharding-algorithm-name: abc
          # 配置订单表的分片策略
          order:
            # 声明订单表所在的真实数据节点（ds0.order、ds1.order）
            actual-data-nodes: ds$->{0..1}.order
            # 配置分库规则
            database-strategy:
              standard:
                # 配置路由键为order_id（数据库中的列名）
                sharding-column: order_id
                # 配置分片算法（使用内置的取模分片算法）
                sharding-algorithm-name: abc
            # 配置订单表的主键生成策略
            key-generate-strategy:
              # 声明主键为order_id
              column: order_id
              # 同样使用之前的雪花算法
              keygenerator-name: global-id-snowflake
          # 配置订单详情表的分片策略
          order_info:
            # 声明商品详情表所在的真实数据节点（ds0.order_info、ds1.order_info）
            actual-data-nodes: ds$->{0..1}.order_info
            # 配置分库规则
            database-strategy:
              standard:
                # 配置路由键为order_id（这里的路由键要和订单表一致）
                sharding-column: order_id
                # 配置分片算法（使用内置的取模分片算法）
                sharding-algorithm-name: abc
            # 配置订单详情表的主键生成策略
            key-generate-strategy:
              # 声明主键为order_info_id
              column: order_info_id
              # 同样使用之前的雪花算法
              keygenerator-name: global-id-snowflake
          # 配置用户详情表的分片策略
          user_info:
            # 声明用户详情表所在的真实数据节点（ds0.user_info、ds1.user_info）
            actual-data-nodes: ds$->{0..1}.user_info
            # 配置用户详情表的主键生成策略
            key-generate-strategy:
              # 声明主键为user_id
              column: user_id
              # 同样使用之前的雪花算法
              keygenerator-name: global-id-snowflake
        sharding-algorithms:
          # 配置前面的分库算法
          abc:
            # 使用ShardingSphere内置的取模算法
            type: MOD
            props:
              # 声明分库的节点数量
              sharding-count: 2
          # 配置哈希取模的分表算法
          key-hash-mod:
            # 使用内置的哈希取模算法
            type: HASH_MOD
            props:
              # 声明分表的节点数量
              sharding-count: 2
        key-generators:
          # 配置上面的主键生成策略
          global-id-snowflake:
            # 选择使用内置的雪花算法
            type: SNOWFLAKE
            props:
              # 分配一个工作节点ID（要确保全局唯一）
              worker-id: 111
        binding-tables:
          # 配置第一组绑定表的关系（订单表、订单详情表）
          - order,order_info
        broadcast-tables:
          - user_info
# ------------------------------------mybatis-plus配置------------------------------------------
mybatis-plus:
  #  mapper-locations: classpath*:**/mapper/*.xml
  type-aliases-package: com.cw.cbs.wh.algorithm.entity.**
  check-config-location: true
  configuration:
    map-underscore-to-camel-case: true
    auto-mapping-behavior: partial
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      logic-delete-value: 1
      logic-not-delete-value: 0
      id-type: input
